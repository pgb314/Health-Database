{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95512e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # normalizacion\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn.linear_model import Lasso        # regularizacion L1\n",
    "from sklearn.linear_model import Ridge        # regularizacion L2\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#!pip install xgboost\n",
    "#!pip install catboost\n",
    "#!pip install lightgbm\n",
    "#!pip install h2o\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR  \n",
    "from sklearn.tree import ExtraTreeRegressor as ETR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "from catboost import CatBoostRegressor as CTR\n",
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea454b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml1():\n",
    "    \n",
    "    models = {'RFR':{'MODEL':RFR(),'PARAM':{'n_estimators': [50,150,500],'max_depth':[1,10,15],'min_weight_fraction_leaf':[0.0,0.1,0.2]}}}\n",
    "              #'XGB':{'MODEL':XGBR(),'PARAM':{'n_estimators': [10, 50, 100, 150, 200, 500],'max_depth': [1, 5,6, 10, 15, 20],'learning_rate':[0.001,0.002,0.01,0.05] }},\n",
    "              #'SVR':{'MODEL':SVR(),'PARAM':{'kernel':['rbf','poly','linear']}},\n",
    "              #'CTR':{'MODEL':CTR(),'PARAM:':{'depth' : [6,8,10],'learning_rate' : [0.01, 0.05, 0.1],'iterations': [30, 50, 100],'subsample' : [0.5, 0.7, 1.0]}},\n",
    "              #'GaussianNB':{'MODEL':GaussianNB(),'PARAM':{'var_smoothing':[1e-09]}},\n",
    "   \n",
    "              #'Lasso':{'MODEL':Lasso(),'PARAM':{'alpha':[0.3,0.5,0.7,0.9,1.0],'max_iter':[800,1000,1200]}}}\n",
    "    \n",
    "    rmse = []\n",
    "    name = []\n",
    "    #b = []\n",
    "    score = []\n",
    "    dfmodels = pd.DataFrame()\n",
    "    \n",
    "    for m in models:\n",
    "        x = models[m][\"MODEL\"]\n",
    "        p = models[m][\"PARAM\"]\n",
    "        y_pred=grid(x,p).predict(X_test)\n",
    "        #best= grid(x,p).best_params_   \n",
    "        #sco = grid(x,p).best_score_\n",
    "        MSE = mse(y_test, y_pred, squared=False)\n",
    "        #score.append(sco)\n",
    "        #b.append(best)\n",
    "        rmse.append(MSE)\n",
    "        name.append(m)\n",
    "        importance = grid(x,p).feature_importances_\n",
    "        for i,v in enumerate(importance):\n",
    "            print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    dfmodels['Modelo'] = name\n",
    "    dfmodels['RMSE'] = rmse\n",
    "    #dfmodels['Best_Parametres'] = b\n",
    "    #dfmodels['bestsco'] = score                        \n",
    "    dfmodels.sort_values(\"RMSE\",ascending=True,inplace=True,ignore_index=True)\n",
    "    print(f'model {dfmodels.Modelo[0]} rmse {dfmodels.RMSE[0]} ')\n",
    "    \n",
    "    \n",
    "    return dfmodels\n",
    "\n",
    "\n",
    "def grid(modelo, param):\n",
    "    \n",
    "    g=GridSearchCV(modelo, # modelo de sklearn\n",
    "                   param,  # dictio de parametros\n",
    "                   cv=5,   # nº de cortes del cross-validation\n",
    "                   return_train_score=True, # error en entrenamiento para checkear\n",
    "                   n_jobs=-1  # usa todos los nucleos disponibles\n",
    "                  )\n",
    "\n",
    "    g.fit(X_train, y_train)\n",
    "    print('Acierto test: {:.2f}'.format(g.score(X_test, y_test)))\n",
    "    print('Acierto train: {:.2f}'.format(g.score(X_train, y_train)))\n",
    "    print('Mejores parametros: {}'.format(g.best_params_))\n",
    "    print('Modelo: {}'.format(modelo))\n",
    "    print('Mejor acierto cv: {:.2f}'.format(g.best_score_))\n",
    "\n",
    "    return g.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f62fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning():\n",
    "    \n",
    "    modelos = {'LinReg':LinReg(), 'Lasso':Lasso(), 'Ridge':Ridge(), 'Elastic':ElasticNet(),'RFR':RFR()}\n",
    "    \n",
    "    nombres = ['LinReg', 'Lasso', 'Ridge', 'Elastic','RFR']\n",
    "    \n",
    "    RMSE = []\n",
    "    R2_test = []\n",
    "    R2_train = []\n",
    "\n",
    "    resumen_modelos = pd.DataFrame()\n",
    "\n",
    "    for m in modelos:\n",
    "     \n",
    "            \n",
    "        mod = modelos[m]\n",
    "        mod.fit(X_train, y_train)\n",
    "\n",
    "        y_pred=mod.predict(X_test)\n",
    "        error = mse(y_test, y_pred, squared=False)\n",
    "\n",
    "        y_pred = mod.predict(X_test)\n",
    "        R2_ts = mod.score(X_test, y_test)\n",
    "        y_pred = mod.predict(X_train) \n",
    "        R2_tr = mod.score(X_train, y_train)\n",
    "\n",
    "        RMSE.append(int(error))\n",
    "        R2_test.append(R2_ts)\n",
    "        R2_train.append(R2_tr)\n",
    "\n",
    "    resumen_modelos['Modelo'] = nombres\n",
    "    resumen_modelos['RMSE'] = RMSE\n",
    "    resumen_modelos['R2_test'] = R2_test\n",
    "    resumen_modelos['R2_train'] = R2_train\n",
    "    \n",
    "    dict_errores = dict(zip(nombres, RMSE))\n",
    "    best = list(dict_errores.keys())[list(dict_errores.values()).index(min(RMSE))] \n",
    "    \n",
    "    modelo = modelos[best]\n",
    "    \n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = modelo.predict(X_test)\n",
    "    R2_test = modelo.score(X_test, y_test)\n",
    "    y_pred = modelo.predict(X_train) \n",
    "    R2_train = modelo.score(X_train, y_train)\n",
    "    \n",
    "    error = round(min(RMSE),2)\n",
    "    R2_train = round(R2_train, 4)\n",
    "    R2_test = round(R2_test, 4)\n",
    "    \n",
    "    if R2_train > (1.15*R2_test):\n",
    "        print(f'Best Model: {best}, RMSE = {error}, R2_train = {R2_train}, R2_test = {R2_test}, OVERFITING (modifica datos)')\n",
    "    \n",
    "    elif R2_train > R2_test:\n",
    "        print(f'Best Model: {best}, RMSE = {error}, R2_train = {R2_train}, R2_test = {R2_test}, LO NORMAL')\n",
    "    \n",
    "    elif R2_train < R2_test:\n",
    "        print(f'Best Model: {best}, RMSE = {error}, R2_train = {R2_train}, R2_test = {R2_test}, UNDERFITING (dame más datos)')\n",
    "        \n",
    "    return modelos[resumen_modelos[\"Modelo\"][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a16509",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [\"Total NCD Deaths (in thousands)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a05666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Elastic, RMSE = 131027, R2_train = 0.7518, R2_test = 0.8617, UNDERFITING (dame más datos)\n",
      "Column: 0, Selected False, Rank: 33.000\n",
      "Column: 1, Selected False, Rank: 30.000\n",
      "Column: 2, Selected False, Rank: 19.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected False, Rank: 6.000\n",
      "Column: 5, Selected False, Rank: 22.000\n",
      "Column: 6, Selected False, Rank: 24.000\n",
      "Column: 7, Selected False, Rank: 5.000\n",
      "Column: 8, Selected False, Rank: 3.000\n",
      "Column: 9, Selected False, Rank: 38.000\n",
      "Column: 10, Selected False, Rank: 27.000\n",
      "Column: 11, Selected True, Rank: 1.000\n",
      "Column: 12, Selected False, Rank: 28.000\n",
      "Column: 13, Selected False, Rank: 4.000\n",
      "Column: 14, Selected False, Rank: 8.000\n",
      "Column: 15, Selected False, Rank: 17.000\n",
      "Column: 16, Selected False, Rank: 34.000\n",
      "Column: 17, Selected False, Rank: 15.000\n",
      "Column: 18, Selected False, Rank: 13.000\n",
      "Column: 19, Selected False, Rank: 25.000\n",
      "Column: 20, Selected False, Rank: 14.000\n",
      "Column: 21, Selected False, Rank: 9.000\n",
      "Column: 22, Selected False, Rank: 7.000\n",
      "Column: 23, Selected True, Rank: 1.000\n",
      "Column: 24, Selected False, Rank: 23.000\n",
      "Column: 25, Selected False, Rank: 29.000\n",
      "Column: 26, Selected False, Rank: 32.000\n",
      "Column: 27, Selected False, Rank: 20.000\n",
      "Column: 28, Selected False, Rank: 12.000\n",
      "Column: 29, Selected False, Rank: 36.000\n",
      "Column: 30, Selected False, Rank: 11.000\n",
      "Column: 31, Selected True, Rank: 1.000\n",
      "Column: 32, Selected False, Rank: 31.000\n",
      "Column: 33, Selected False, Rank: 2.000\n",
      "Column: 34, Selected False, Rank: 16.000\n",
      "Column: 35, Selected False, Rank: 10.000\n",
      "Column: 36, Selected False, Rank: 26.000\n",
      "Column: 37, Selected True, Rank: 1.000\n",
      "Column: 38, Selected False, Rank: 18.000\n",
      "Column: 39, Selected False, Rank: 39.000\n",
      "Column: 40, Selected False, Rank: 21.000\n",
      "Column: 41, Selected False, Rank: 37.000\n",
      "Column: 42, Selected False, Rank: 35.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dic1 = {}\n",
    "for i in factors:\n",
    "    df1=pd.read_csv(f\"C:\\\\Users\\\\pabli\\\\Desktop\\\\Health-Database\\\\data\\\\Df_modeling2\\\\threshold4.csv\")\n",
    "    df1.drop(columns=\"Unnamed: 0\",inplace=True)\n",
    "    df1_ = df1.drop(columns=i).columns\n",
    "    scaler=StandardScaler()\n",
    "    df1[df1_]=scaler.fit_transform(df1[df1_])\n",
    "    X = df1.drop(columns=i)\n",
    "    y = df1[i]\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, train_size=0.9, test_size=0.1, random_state=42)\n",
    "    rfe = RFE(estimator=machine_learning(), n_features_to_select=5)\n",
    "    rfe.fit(X, y)\n",
    "    for t in range(X.shape[1]):\n",
    "        print('Column: %d, Selected %s, Rank: %.3f' % (t, rfe.support_[t], rfe.ranking_[t]))\n",
    "    d1 = []\n",
    "    for t in range(X.shape[1]):\n",
    "        if rfe.support_[t] == True:\n",
    "            d1.append(t)\n",
    "    dic1[y.name]= d1\n",
    "    df = df1.iloc[:,dic1[y.name]]\n",
    "    try:\n",
    "        df.to_csv(f\"C:\\\\Users\\\\pabli\\\\Desktop\\\\Health-Database\\\\data\\\\thresh4_models\\\\{i}.csv\")\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78e2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3744370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cbfa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44342.73\n",
      "Total NCD Deaths (in thousands)\n",
      "44342.73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn.linear_model import Lasso        # regularizacion L1\n",
    "from sklearn.linear_model import Ridge        # regularizacion L2\n",
    "from sklearn.linear_model import ElasticNet as Elastic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR  \n",
    "from sklearn.tree import ExtraTreeRegressor as ETR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "from catboost import CatBoostRegressor as CTR\n",
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "\n",
    "\n",
    "# assign directory\n",
    "\n",
    "\n",
    "directory = r'C:\\Users\\pabli\\Desktop\\Health-Database\\data\\thresh4_models'\n",
    "filename = 'Total NCD Deaths (in thousands).csv'\n",
    "mod = {\"Adolescent birth rate (per 1000 women aged 15-19 years)\":RFR(),\n",
    " \"Age-standardized suicide rates (per 100 000 population)\":Lasso(),\n",
    " \"Estimates of rates of homicides per 100 000 population\":RFR(),\n",
    " \"Prevalence of controlled hypertension among adults aged 30-79 years with hypertension, age-standardized\":RFR(),\n",
    " \"Total NCD Deaths (in thousands)\":Elastic()}\n",
    "\n",
    "\n",
    "\n",
    "f = os.path.join(directory, filename)\n",
    "if os.path.isfile(f):\n",
    "    df = pd.read_csv(f)\n",
    "    df1 = pd.read_csv(r\"C:\\Users\\pabli\\Desktop\\Health-Database\\data\\clean_full_data.csv\")\n",
    "    lst = df1[filename.split(\".c\")[0]]\n",
    "    print(lst[0])\n",
    "    file = filename.split(\".c\")[0]\n",
    "    df[file]=lst\n",
    "    print(file)\n",
    "    print(df[file][0])\n",
    "    X = df.drop(columns=file)\n",
    "    y = df[file]\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    mo = mod[file]\n",
    "    mo.fit(X_train, y_train)\n",
    "    pickle.dump(mo, open(f'model_{file}.pkl', 'wb'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e9745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(f\"C:\\\\Users\\\\pabli\\\\Desktop\\\\Health-Database\\\\data\\\\Df_modeling2\\\\threshold4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27285ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      44342.7300\n",
       "1      44521.9100\n",
       "2      47583.4600\n",
       "3      95631.1200\n",
       "4      97079.5500\n",
       "          ...    \n",
       "3073   26388.9800\n",
       "3074   46639.9900\n",
       "3075   25688.8600\n",
       "3076   20001.7700\n",
       "3077   20456.0600\n",
       "Name: Total NCD Deaths (in thousands), Length: 3078, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Total NCD Deaths (in thousands)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ec79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "health"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
